{
  "hash": "ae4c7a03cd68691500fcc54251a609e9",
  "result": {
    "markdown": "---\ntitle: <b>Decision Tree Classifier for Twitter Data</b>\nformat:\n  html:\n    theme: lumen\n    toc: true\n    self-contained: true\n    embed-resources: true\n    page-layout: full\n    code-fold: true\n    code-tools: true\n---\n\n# Import Libraries\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as  pd\nfrom scipy import stats\nfrom sklearn.model_selection import train_test_split\n\nimport nltk\nfrom PIL import Image\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\n\nfrom sklearn.tree import plot_tree\nfrom sklearn.utils import resample\n\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn import metrics\n\nfrom sklearn import metrics\nfrom sklearn.metrics import confusion_matrix\n\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\n\nimport warnings \nwarnings.filterwarnings(\"ignore\")\n\nimport re\n```\n:::\n\n\n# Import Data\n- The data has over 3900 English tweets from the past 7 days of the current 10 teams.\n- The 10 teams are: \n    1. Ferrari\n    2. Mercedes\n    3. Redbull\n    4. Haas\n    5. Mclaren\n    6. Alpine\n    7. Williams\n    8. Aston Martin\n    9. Alpha Tauri\n    10. Alfa Romeo\n- The data is also cleaned to an extent by removing punctuations in the previous sections when sentiments of these tweets were extracted.\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\ndf = pd.read_csv('../../data/01-modified-data/all_teams_sentiment_df.csv')\ndf.drop(['Unnamed: 0'], axis=1, inplace=True)\ndf.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=2}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Team</th>\n      <th>0</th>\n      <th>text</th>\n      <th>polarity</th>\n      <th>subjectivity</th>\n      <th>sentiment</th>\n      <th>tokenized</th>\n      <th>nonstop</th>\n      <th>stemmed</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Ferrari</td>\n      <td>*female f1 fans reposting shirtless driver pic...</td>\n      <td>female f fans reposting shirtless driver pics ...</td>\n      <td>0.04</td>\n      <td>0.673333</td>\n      <td>positive</td>\n      <td>['female', 'f', 'fans', 'reposting', 'shirtles...</td>\n      <td>['female', 'f', 'fans', 'reposting', 'shirtles...</td>\n      <td>['femal', 'f', 'fan', 'repost', 'shirtless', '...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Ferrari</td>\n      <td>Watch a video explaining Ferrari's development...</td>\n      <td>watch a video explaining ferraris development ...</td>\n      <td>0.35</td>\n      <td>0.550000</td>\n      <td>neutral</td>\n      <td>['watch', 'a', 'video', 'explaining', 'ferrari...</td>\n      <td>['watch', 'video', 'explaining', 'ferraris', '...</td>\n      <td>['watch', 'video', 'explain', 'ferrari', 'deve...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Ferrari</td>\n      <td>[Race Fans]\\nFerrari engine’s driveability is ...</td>\n      <td>race fans\\nferrari engine’s driveability is bi...</td>\n      <td>0.00</td>\n      <td>0.000000</td>\n      <td>neutral</td>\n      <td>['race', 'fans', 'ferrari', 'engine', 's', 'dr...</td>\n      <td>['race', 'fans', 'ferrari', 'engine', 'driveab...</td>\n      <td>['race', 'fan', 'ferrari', 'engin', 'driveabl'...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Ferrari</td>\n      <td>Ferrari boss Binotto set for talks with Schuma...</td>\n      <td>ferrari boss binotto set for talks with schuma...</td>\n      <td>0.00</td>\n      <td>0.125000</td>\n      <td>neutral</td>\n      <td>['ferrari', 'boss', 'binotto', 'set', 'for', '...</td>\n      <td>['ferrari', 'boss', 'binotto', 'set', 'talks',...</td>\n      <td>['ferrari', 'boss', 'binotto', 'set', 'talk', ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Ferrari</td>\n      <td>Leclerc: F1 world championship drought not pre...</td>\n      <td>leclerc f world championship drought not press...</td>\n      <td>0.00</td>\n      <td>0.000000</td>\n      <td>positive</td>\n      <td>['leclerc', 'f', 'world', 'championship', 'dro...</td>\n      <td>['leclerc', 'f', 'world', 'championship', 'dro...</td>\n      <td>['leclerc', 'f', 'world', 'championship', 'dro...</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n# Data Pre-Processing and Visualization\n- While cleaning tweets previously, numbers were also removed which in turn converted \"f1\" to \"f\". I rectified those mistakes by replacing \"f\" with \"f1\". \n- Further, all the newline characters were replaced by spaces by the use of regex library. Lastly, all commas, brackets and apostrophes were also removed.\n- Distribution of labels were also visualization to check if any downsampling needs to be performed.\n- The label column was converted to numerical values by mapping each team to a number.\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\ndf = df[['Team', 'text']]\ndf.head(10)\n```\n\n::: {.cell-output .cell-output-display execution_count=3}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Team</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Ferrari</td>\n      <td>female f fans reposting shirtless driver pics ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Ferrari</td>\n      <td>watch a video explaining ferraris development ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Ferrari</td>\n      <td>race fans\\nferrari engine’s driveability is bi...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Ferrari</td>\n      <td>ferrari boss binotto set for talks with schuma...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Ferrari</td>\n      <td>leclerc f world championship drought not press...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Ferrari</td>\n      <td>shop now charles leclerc ferrari  f tshirt   d...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Ferrari</td>\n      <td>leclerc f world championship drought not press...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Ferrari</td>\n      <td>new racefans roundup  ferrari engine’s driveab...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Ferrari</td>\n      <td>fhistoria but ferrari drive</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Ferrari</td>\n      <td>fsofi as a ferrari fan my only plans for the w...</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\nfor i in range(len(df)):\n    \n    df['text'][i] = df['text'][i].replace(\" f \", \" f1 \")\n    df['text'][i] = re.sub('\\n', ' ', df['text'][i])\n    df['text'][i].replace(\",\",\"\").replace(\"[\",\"\").replace(\"]\",\"\").replace(\"'\",\"\")\n    \ndf.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=4}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Team</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Ferrari</td>\n      <td>female f1 fans reposting shirtless driver pics...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Ferrari</td>\n      <td>watch a video explaining ferraris development ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Ferrari</td>\n      <td>race fans ferrari engine’s driveability is big...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Ferrari</td>\n      <td>ferrari boss binotto set for talks with schuma...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Ferrari</td>\n      <td>leclerc f1 world championship drought not pres...</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\nfig, ax = plt.subplots(figsize=(8, 4))\n\nsns.barplot(x = df['Team'].value_counts().index, y = df['Team'].value_counts().values, ax=ax)\n\nax.set_xlabel('Team')\nax.set_ylabel('Number of Tweets')\nax.set_title('Number of Tweets per Team')\nax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha=\"right\")\n```\n\n::: {.cell-output .cell-output-display execution_count=5}\n```\n[Text(0, 0, 'Williams'),\n Text(1, 0, 'Mclaren'),\n Text(2, 0, 'Mercedes'),\n Text(3, 0, 'Alpine'),\n Text(4, 0, 'Ferrari'),\n Text(5, 0, 'Haas'),\n Text(6, 0, 'Redbull'),\n Text(7, 0, 'Aston Martin'),\n Text(8, 0, 'Alfa Romeo'),\n Text(9, 0, 'Alpha Tauri')]\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](DT_files/figure-html/cell-6-output-2.png){width=668 height=432}\n:::\n:::\n\n\nThe distribution of tweets as can be seen is not uniform but the difference in minimum and maximum number of tweets per team is not too high hence no downsampling is performed. \n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\nX = df['text']\ny = df['Team']\n```\n:::\n\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\nlabelencoder = LabelEncoder()\ny = labelencoder.fit_transform(y)\ny\n```\n\n::: {.cell-output .cell-output-display execution_count=7}\n```\narray([4, 4, 4, ..., 0, 0, 0])\n```\n:::\n:::\n\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\nteams = ['Ferrari', 'Mercedes', 'Redbull', 'Haas', 'Mclaren', 'Alpine', 'Williams', 'Aston Martin', 'Alpha Tauri', 'Alfa Romeo']\ny1 = labelencoder.fit(teams)\nlabel_map = dict(zip(y1.classes_, y1.transform(y1.classes_)))\nlabel_map\n```\n\n::: {.cell-output .cell-output-display execution_count=8}\n```\n{'Alfa Romeo': 0,\n 'Alpha Tauri': 1,\n 'Alpine': 2,\n 'Aston Martin': 3,\n 'Ferrari': 4,\n 'Haas': 5,\n 'Mclaren': 6,\n 'Mercedes': 7,\n 'Redbull': 8,\n 'Williams': 9}\n```\n:::\n:::\n\n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\nlabel_list = list(label_map.keys())\n```\n:::\n\n\n# Decision Tree Model\n\n- The data which comes from e-commerce site is unstructured text data. Text mining is becoming an important field in research for finding valuable information from unstructured texts. Data which contains an unstructured text which stores large volume of valuable information cannot exclusively be used for any process by computers.\n- Decision tree builds classification models in the form of a tree structure. It breaks down a dataset into smaller and smaller subsets while at the same time an associated decision tree is incrementally developed. The final result is a tree with decision nodes and leaf nodes. Decision Trees usually implement exactly the human thinking ability while making a decision, so it is easy to understand.\n- The logic behind the decision tree can be easily understood because it shows a flow chart type structure /tree-like structure which makes it easy to visualize and extract information out of the background process.\n- While building a Decision tree, the main thing is to select the best attribute from the total features list of the dataset for the root node as well as for sub-nodes. The selection of best attributes is being achieved with the help of a technique known as the Attribute selection measure (ASM). There are two techniques for ASM:\n    1. Information Gain (Entropy) - It is the measurement of changes in entropy value after the splitting/segmentation of the dataset based on an attribute.\n    2. Gini Impurity - It is defined as a measure of impurity/ purity used while creating a decision tree in the CART(known as Classification and Regression Tree) algorithm.\n- The basic idea behind any decision tree algorithm is as follows:\n    1. Select the best Feature using Attribute Selection Measures(ASM) to split the records.\n    2. Make that attribute/feature a decision node and break the dataset into smaller subsets.\n    3. Start the tree-building process by repeating this process recursively for each child until one of the following condition is being achieved :\n        - All tuples belonging to the same attribute value.\n        - There are no more of the attributes remaining.\n        - There are no more instances remaining.\n\n## Data Preparation\n\n- `Count Vectorizer`: It is used to transform a given text into a vector on the basis of the frequency (count) of each word that occurs in the entire text. This is helpful when we have multiple such texts, and we wish to convert each word in each text into vectors (for using in further text analysis). CountVectorizer creates a matrix in which each unique word is represented by a column of the matrix, and each text sample from the document is a row in the matrix. The value of each cell is nothing but the count of the word in that particular text sample.\n\n- The data is first split into train and test with a split ratio of 80(train) - 20(test). The tweets are then transformed to number vectors using sklearn CountVectorizer function.\n\n::: {.cell execution_count=10}\n``` {.python .cell-code}\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)\n```\n:::\n\n\n::: {.cell execution_count=11}\n``` {.python .cell-code}\nvectorizer = CountVectorizer()\nX_train1 = vectorizer.fit_transform(X_train.astype('U')) \nX_test1 = vectorizer.transform(X_test.astype('U'))\n```\n:::\n\n\n## Decision Trees with random Hyperparameters\n\n### Decision Tree 1\n\nHyperparameters: <br>\n- Criterion: Entropy <br>\n- Splitter: Best <br>\n- Maximum depth of the decision tree: 4\n\n::: {.cell execution_count=12}\n``` {.python .cell-code}\ndt1 = DecisionTreeClassifier(random_state=1973,criterion = \"entropy\", splitter = \"best\", max_depth = 4)\ndt1.fit(X_train1, y_train)\ny_pred = dt1.predict(X_test1)\nClassification_report_1 = classification_report(y_test, y_pred)\nconf_matrix_1 = confusion_matrix(y_test, y_pred)\n```\n:::\n\n\nDecision Tree 1 Plot after fitting:\n\n::: {.cell execution_count=13}\n``` {.python .cell-code}\nplt.figure(figsize = (30,30))\ndec_tree_1 = plot_tree(decision_tree=dt1, class_names=label_list, filled=True, rounded=True, fontsize=10, max_depth=4)\n```\n\n::: {.cell-output .cell-output-display}\n![](DT_files/figure-html/cell-14-output-1.png){width=2403 height=2237}\n:::\n:::\n\n\nClassification Report for Decision Tree 1:\n\n::: {.cell execution_count=14}\n``` {.python .cell-code}\n#Confusion matrix seaborn\nsns.heatmap(conf_matrix_1,annot=True)\nplt.xlabel('Original')\nplt.ylabel('Predicted')\nplt.title('Heatmap of Confusion Matrix 1: Entropy, Best')\n#plt.savefig('Confusion_Matrix1.png')\n\n#Accuracy\nprint('Accuracy',metrics.accuracy_score(y_test,y_pred))\nprint(classification_report(y_test,y_pred))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAccuracy 0.5381679389312977\n              precision    recall  f1-score   support\n\n           0       0.50      0.02      0.05        41\n           1       0.16      0.12      0.14        24\n           2       0.61      0.87      0.72        77\n           3       0.00      0.00      0.00        55\n           4       0.87      0.83      0.85        90\n           5       0.00      0.00      0.00        91\n           6       0.87      0.85      0.86       113\n           7       0.90      0.77      0.83        99\n           8       0.60      0.11      0.19        81\n           9       0.27      0.83      0.40       115\n\n    accuracy                           0.54       786\n   macro avg       0.48      0.44      0.40       786\nweighted avg       0.53      0.54      0.48       786\n\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](DT_files/figure-html/cell-15-output-2.png){width=547 height=449}\n:::\n:::\n\n\nInference from Decision Tree 1: <br>\n- There are lot of mis-classifications for 6 out of 10 Teams (classes).<br>\n- Teams such as Alpine, Ferrari, Mclaren and Mercedes are getting classified with a high F1 score.<br>\n- A majority of tweets are classified into label 9 (Williams). One of the reasons can be since the samples of Williams are higher than other classes.<br>\n\n### Decision Tree 2\nHyperparameters:<br>\n- Criterion: Gini Impurity<br>\n- Splitter: Random<br>\n- Maximum depth of the decision tree: 5<br>\n\n::: {.cell execution_count=15}\n``` {.python .cell-code}\ndt2 = DecisionTreeClassifier(random_state=10,criterion = \"gini\", splitter = \"random\",max_depth = 5)\ndt2.fit(X_train1, y_train)\ny_pred = dt2.predict(X_test1)\nClassification_report_2 = classification_report(y_test, y_pred)\nconf_matrix_2 = confusion_matrix(y_test, y_pred)\n```\n:::\n\n\nDecision Tree 2 Plot after fitting:\n\n::: {.cell execution_count=16}\n``` {.python .cell-code}\nplt.figure(figsize = (30,30))\ndec_tree_2 = plot_tree(decision_tree=dt2, class_names=label_list, filled=True, rounded=True, fontsize=10, max_depth=5)\n```\n\n::: {.cell-output .cell-output-display}\n![](DT_files/figure-html/cell-17-output-1.png){width=2465 height=2237}\n:::\n:::\n\n\nClassification Report for Decision Tree 2:\n\n::: {.cell execution_count=17}\n``` {.python .cell-code}\n#Confusion matrix seaborn\nsns.heatmap(conf_matrix_2,annot=True)\nplt.xlabel('Original')\nplt.ylabel('Predicted')\nplt.title('Heatmap of Confusion Matrix 2: Gini, Random')\n#plt.savefig('Confusion_Matrix2.png')\n\n#Accuracy\nprint('Accuracy',metrics.accuracy_score(y_test,y_pred))\nprint(classification_report(y_test,y_pred))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAccuracy 0.5928753180661578\n              precision    recall  f1-score   support\n\n           0       0.00      0.00      0.00        41\n           1       0.00      0.00      0.00        24\n           2       0.59      0.84      0.70        77\n           3       0.00      0.00      0.00        55\n           4       0.28      0.89      0.42        90\n           5       0.20      0.05      0.09        91\n           6       0.88      0.82      0.85       113\n           7       0.89      0.75      0.81        99\n           8       0.87      0.89      0.88        81\n           9       0.88      0.67      0.76       115\n\n    accuracy                           0.59       786\n   macro avg       0.46      0.49      0.45       786\nweighted avg       0.57      0.59      0.55       786\n\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](DT_files/figure-html/cell-18-output-2.png){width=547 height=449}\n:::\n:::\n\n\nInference from Decision Tree 2: <br>\n- There are lot of mis-classifications for 5 out of 10 Teams (classes).<br>\n- Teams such as Alpine, Mclaren, Mercedes, Redbull and Williams are getting classified with a high F1 score.<br>\n- A majority of tweets are classified into label 4 (Ferrari).<br>\n- As I increased our maximum depth by 1, we can see a significant change in the classification for Williams label as well as for some other classes.<br>\n\n### Decision Tree 3\nHyperparameters:\n- Criterion: Entropy\n- Splitter: Random\n- Maximum depth of the decision tree: 4\n\n::: {.cell execution_count=18}\n``` {.python .cell-code}\ndt3 = DecisionTreeClassifier(random_state=0,criterion = \"entropy\", splitter = \"random\",max_depth = 4)\ndt3.fit(X_train1, y_train)\ny_pred = dt3.predict(X_test1)\nClassification_report_3 = classification_report(y_test, y_pred)\nconf_matrix_3 = confusion_matrix(y_test, y_pred)\n```\n:::\n\n\nDecision Tree 3 Plot after fitting:\n\n::: {.cell execution_count=19}\n``` {.python .cell-code}\nplt.figure(figsize = (60,40))\ndec_tree_3 = plot_tree(decision_tree=dt3, class_names=label_list, filled=True, rounded=True, fontsize=10, max_depth=4)\n```\n\n::: {.cell-output .cell-output-display}\n![](DT_files/figure-html/cell-20-output-1.png){width=4517 height=2976}\n:::\n:::\n\n\nClassification Report for Decision Tree 3:\n\n::: {.cell execution_count=20}\n``` {.python .cell-code}\n#Confusion matrix seaborn\nsns.heatmap(conf_matrix_3,annot=True)\nplt.xlabel('Original')\nplt.ylabel('Predicted')\nplt.title('Heatmap of Confusion Matrix 3: Gini, Random')\n#plt.savefig('Confusion_Matrix3.png')\n\n#Accuracy\nprint('Accuracy',metrics.accuracy_score(y_test,y_pred))\nprint(classification_report(y_test,y_pred))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAccuracy 0.5190839694656488\n              precision    recall  f1-score   support\n\n           0       0.00      0.00      0.00        41\n           1       0.16      0.12      0.14        24\n           2       0.61      0.87      0.72        77\n           3       0.00      0.00      0.00        55\n           4       0.00      0.00      0.00        90\n           5       0.88      0.69      0.77        91\n           6       0.87      0.85      0.86       113\n           7       0.90      0.77      0.83        99\n           8       0.60      0.11      0.19        81\n           9       0.25      0.82      0.39       115\n\n    accuracy                           0.52       786\n   macro avg       0.43      0.42      0.39       786\nweighted avg       0.50      0.52      0.47       786\n\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](DT_files/figure-html/cell-21-output-2.png){width=547 height=449}\n:::\n:::\n\n\nInference from Decision Tree 3: \n- There are lot of mis-classifications for 6 out of 10 Teams (classes).<br>\n- Teams such as Alpine, Haas, Mclaren and Mercedes are getting classified with a high F1 score.<br>\n- A majority of tweets are classified into label 9 (Williams).<br>\n- Comparing with Decision tree 1, after changing our splitter to random from best our accuracy has decreased so the splitter that was chosen earlier in the first tree is more suitable.<br>\n\n## Hyperparameter Tuning\n- Since the accuracy scores of the Decision tree models with random hyperparameters were not up to the mark we have to tune our hyperparameters accordingly.\n- From above random models, it is concluded that even if Entropy performs better feature selection, the difference is less when we compare to Gini Impurity. This is not the case for computational time, which is higher when we take Entropy as our criterion.\n- It is also observed that increasing the depth of the decision tree leads to better results but it also increases the complexity of the model and thus may lead to overfitting. Hence we need to find an optimal depth for our decision tree model.\n- This can be achieved by iterating with the help of loops over depth ranging from 0-20 and finding the accuracy and recall for all the depths.\n\n::: {.cell execution_count=21}\n``` {.python .cell-code}\ntest_results=[]\ntrain_results=[]\n\nfor num_layer in range(1,20):\n    model = DecisionTreeClassifier(max_depth=num_layer)\n    model = model.fit(X_train1, y_train)\n\n    yp_train=model.predict(X_train1)\n    yp_test=model.predict(X_test1)\n\n    # print(y_pred.shape)\n    test_results.append([num_layer,accuracy_score(y_test, yp_test),recall_score(y_test, yp_test,pos_label=0, average='micro'),recall_score(y_test, yp_test,pos_label=1, average='micro'),\n                         recall_score(y_test, yp_test,pos_label=2, average='micro'),recall_score(y_test, yp_test,pos_label=3, average='micro'),\n                         recall_score(y_test, yp_test,pos_label=4, average='micro'),recall_score(y_test, yp_test,pos_label=5, average='micro'),\n                         recall_score(y_test, yp_test,pos_label=6, average='micro'),recall_score(y_test, yp_test,pos_label=7, average='micro'),\n                         recall_score(y_test, yp_test,pos_label=8, average='micro'),recall_score(y_test, yp_test,pos_label=9, average='micro')])\n    train_results.append([num_layer,accuracy_score(y_train, yp_train),recall_score(y_train, yp_train,pos_label=0, average='micro'),recall_score(y_train, yp_train,pos_label=1, average='micro'),\n                          recall_score(y_train, yp_train,pos_label=2, average='micro'),recall_score(y_train, yp_train,pos_label=3, average='micro'),\n                          recall_score(y_train, yp_train,pos_label=4, average='micro'),recall_score(y_train, yp_train,pos_label=5, average='micro'),\n                          recall_score(y_train, yp_train,pos_label=6, average='micro'),recall_score(y_train, yp_train,pos_label=7, average='micro'),\n                          recall_score(y_train, yp_train,pos_label=8, average='micro'),recall_score(y_train, yp_train,pos_label=9, average='micro')])\n```\n:::\n\n\n::: {.cell execution_count=22}\n``` {.python .cell-code}\nplt.plot([x[0] for x in test_results],[x[1] for x in test_results],label='test', color='red', marker='o')\nplt.plot([x[0] for x in train_results],[x[1] for x in train_results],label='train', color='blue', marker='o')\nplt.xlabel('Number of layers in decision tree (max_depth)')\nplt.ylabel('ACCURACY : Training (blue) and Test (red)')\nplt.show()\n\nplt.plot([x[0] for x in test_results],[x[2] for x in test_results],label='test', color='red', marker='o')\nplt.plot([x[0] for x in train_results],[x[2] for x in train_results],label='train', color='blue', marker='o')\nplt.xlabel('Number of layers in decision tree (max_depth)')\nplt.ylabel('RECALL (Y=0): Training (blue) and Test (red)')\nplt.show()\n\nplt.plot([x[0] for x in test_results],[x[3] for x in test_results],label='test', color='red', marker='o')\nplt.plot([x[0] for x in train_results],[x[3] for x in train_results],label='train', color='blue', marker='o')\nplt.xlabel('Number of layers in decision tree (max_depth)')\nplt.ylabel('RECALL (Y=1): Training (blue) and Test (red)')\nplt.show()\n\nplt.plot([x[0] for x in test_results],[x[4] for x in test_results],label='test', color='red', marker='o')\nplt.plot([x[0] for x in train_results],[x[4] for x in train_results],label='train', color='blue', marker='o')\nplt.xlabel('Number of layers in decision tree (max_depth)')\nplt.ylabel('RECALL (Y=2): Training (blue) and Test (red)')\nplt.show()\n\nplt.plot([x[0] for x in test_results],[x[5] for x in test_results],label='test', color='red', marker='o')\nplt.plot([x[0] for x in train_results],[x[5] for x in train_results],label='train', color='blue', marker='o')\nplt.xlabel('Number of layers in decision tree (max_depth)')\nplt.ylabel('RECALL (Y=3): Training (blue) and Test (red)')\nplt.show()\n\nplt.plot([x[0] for x in test_results],[x[6] for x in test_results],label='test', color='red', marker='o')\nplt.plot([x[0] for x in train_results],[x[6] for x in train_results],label='train', color='blue', marker='o')\nplt.xlabel('Number of layers in decision tree (max_depth)')\nplt.ylabel('RECALL (Y=4): Training (blue) and Test (red)')\nplt.show()\n\nplt.plot([x[0] for x in test_results],[x[7] for x in test_results],label='test', color='red', marker='o')\nplt.plot([x[0] for x in train_results],[x[7] for x in train_results],label='train', color='blue', marker='o')\nplt.xlabel('Number of layers in decision tree (max_depth)')\nplt.ylabel('RECALL (Y=5): Training (blue) and Test (red)')\nplt.show()\n\nplt.plot([x[0] for x in test_results],[x[8] for x in test_results],label='test', color='red', marker='o')\nplt.plot([x[0] for x in train_results],[x[8] for x in train_results],label='train', color='blue', marker='o')\nplt.xlabel('Number of layers in decision tree (max_depth)')\nplt.ylabel('RECALL (Y=6): Training (blue) and Test (red)')\nplt.show()\n\nplt.plot([x[0] for x in test_results],[x[9] for x in test_results],label='test', color='red', marker='o')\nplt.plot([x[0] for x in train_results],[x[9] for x in train_results],label='train', color='blue', marker='o')\nplt.xlabel('Number of layers in decision tree (max_depth)')\nplt.ylabel('RECALL (Y=7): Training (blue) and Test (red)')\nplt.show()\n\nplt.plot([x[0] for x in test_results],[x[10] for x in test_results],label='test', color='red', marker='o')\nplt.plot([x[0] for x in train_results],[x[10] for x in train_results],label='train', color='blue', marker='o')\nplt.xlabel('Number of layers in decision tree (max_depth)')\nplt.ylabel('RECALL (Y=8): Training (blue) and Test (red)')\nplt.show()\n\nplt.plot([x[0] for x in test_results],[x[11] for x in test_results],label='test', color='red', marker='o')\nplt.plot([x[0] for x in train_results],[x[11] for x in train_results],label='train', color='blue', marker='o')\nplt.xlabel('Number of layers in decision tree (max_depth)')\nplt.ylabel('RECALL (Y=9): Training (blue) and Test (red)')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](DT_files/figure-html/cell-23-output-1.png){width=589 height=434}\n:::\n\n::: {.cell-output .cell-output-display}\n![](DT_files/figure-html/cell-23-output-2.png){width=589 height=434}\n:::\n\n::: {.cell-output .cell-output-display}\n![](DT_files/figure-html/cell-23-output-3.png){width=589 height=434}\n:::\n\n::: {.cell-output .cell-output-display}\n![](DT_files/figure-html/cell-23-output-4.png){width=589 height=434}\n:::\n\n::: {.cell-output .cell-output-display}\n![](DT_files/figure-html/cell-23-output-5.png){width=589 height=434}\n:::\n\n::: {.cell-output .cell-output-display}\n![](DT_files/figure-html/cell-23-output-6.png){width=589 height=434}\n:::\n\n::: {.cell-output .cell-output-display}\n![](DT_files/figure-html/cell-23-output-7.png){width=589 height=434}\n:::\n\n::: {.cell-output .cell-output-display}\n![](DT_files/figure-html/cell-23-output-8.png){width=589 height=434}\n:::\n\n::: {.cell-output .cell-output-display}\n![](DT_files/figure-html/cell-23-output-9.png){width=589 height=434}\n:::\n\n::: {.cell-output .cell-output-display}\n![](DT_files/figure-html/cell-23-output-10.png){width=589 height=434}\n:::\n\n::: {.cell-output .cell-output-display}\n![](DT_files/figure-html/cell-23-output-11.png){width=589 height=434}\n:::\n:::\n\n\nInference for Hyperparameter tuning<br>\n- As the depth increases, the accuracy and recall scores are increasing.<br>\n- The accuracy and recall scores of test data reach their maximum at max_depth value = 10.<br>\n- The accuracy and recall scores of train data keep on increasing as the depth increases.<br>\n- Hence I choose my optimal max_depth value as 10.<br>\n\n## Optimal Decision Tree\n\n::: {.cell execution_count=23}\n``` {.python .cell-code}\noptimal_dt = DecisionTreeClassifier(random_state=1973, max_depth = 10, criterion = 'gini')\noptimal_dt.fit(X_train1, y_train)\ny_pred = optimal_dt.predict(X_test1)\nClassification_report = classification_report(y_test, y_pred)\nconf_matrix = confusion_matrix(y_test, y_pred)\n```\n:::\n\n\nOptimal Decision Tree Plot after fitting:\n\n::: {.cell execution_count=24}\n``` {.python .cell-code}\nplt.figure(figsize = (40,40))\noptimal_dec_tree = plot_tree(decision_tree=optimal_dt, class_names=label_list, filled=True, rounded=True, fontsize=10, max_depth=10)\n#plt.savefig('dec_tree_4.png')\n```\n\n::: {.cell-output .cell-output-display}\n![](DT_files/figure-html/cell-25-output-1.png){width=3229 height=2976}\n:::\n:::\n\n\nClassification report for Optimal Decision Tree:\n\n::: {.cell execution_count=25}\n``` {.python .cell-code}\nsns.heatmap(conf_matrix,annot=True)\nplt.xlabel('Original')\nplt.ylabel('Predicted')\nplt.title('Heatmap of Optimal Decision Tree')\n#plt.savefig('Confusion_Matrix3.png')\n\n#Accuracy\nprint('Accuracy',metrics.accuracy_score(y_test,y_pred))\nprint(classification_report(y_test,y_pred))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAccuracy 0.7417302798982188\n              precision    recall  f1-score   support\n\n           0       0.70      0.73      0.71        41\n           1       0.48      0.58      0.53        24\n           2       0.62      0.71      0.66        77\n           3       0.98      0.75      0.85        55\n           4       0.78      0.79      0.78        90\n           5       0.79      0.67      0.73        91\n           6       0.87      0.75      0.81       113\n           7       0.83      0.69      0.75        99\n           8       0.85      0.84      0.84        81\n           9       0.58      0.78      0.67       115\n\n    accuracy                           0.74       786\n   macro avg       0.75      0.73      0.73       786\nweighted avg       0.76      0.74      0.75       786\n\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](DT_files/figure-html/cell-26-output-2.png){width=547 height=449}\n:::\n:::\n\n\n## Conclusion\nThe accuracy and recall scores have increased to around 74% by changing our max_depth to 10 and criterion as gini with best splitter.\n\n",
    "supporting": [
      "DT_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}