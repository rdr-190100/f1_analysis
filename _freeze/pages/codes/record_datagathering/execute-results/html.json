{
  "hash": "facf428b99ee76026ea3b5af73b0972b",
  "result": {
    "markdown": "---\ntitle: <b>Record Data Gathering</b>\nformat:\n  html:\n    theme: lumen\n    toc: true\n    self-contained: true\n    embed-resources: true\n    page-layout: full\n    code-fold: true\n    code-tools: true\n---\n\n# Data Gathering\n\n- Data Gathering and Pre-Processing is a very important step in any Data science project pipeline. It is undeniable that 80% of a data scientist's time and effort is spent in collecting, cleaning and preparing the data for analysis because datasets come in various sizes and are different in nature. It is extremely important for a data scientist to reshape and refine the datasets into usable datasets, which can be leveraged for analytics.\n- Knowledge is power, information is knowledge, and data is information in digitized form, at least as defined in IT. Hence, data is power. But before you can leverage that data into a successful strategy for your organization or business, you need to gather it. That’s your first step.\n- Before we define what is data collection, it’s essential to ask the question, “What is data?” The abridged answer is, data is various kinds of information formatted in a particular way. Therefore, data collection is the process of gathering, measuring, and analyzing accurate data from a variety of relevant sources to find answers to research problems, answer questions, evaluate outcomes, and forecast trends and probabilities.\n- Our society is highly dependent on data, which underscores the importance of collecting it. Accurate data collection is necessary to make informed business decisions, ensure quality assurance, and keep research integrity.\n- During data collection, the researchers must identify the data types, the sources of data, and what methods are being used. We will soon see that there are many different data collection methods. There is heavy reliance on data collection in research, commercial, and government fields.\n- `Why Do We Need Data Collection?`\n    - Before a judge makes a ruling in a court case or a general creates a plan of attack, they must have as many relevant facts as possible. The best courses of action come from informed decisions, and information and data are synonymous.\n    - The concept of data collection isn’t a new one but the world has changed. There is far more data available today, and it exists in forms that were unheard of a century ago. The data collection process has had to change and grow with the times, keeping pace with technology.\n    - Whether you’re in the world of academia, trying to conduct research, or part of the commercial sector, thinking of how to promote a new product, you need data collection to help you make better choices.\n- `What Are the Different Methods of Data Collection?`\n    - Surveys\n    - Transactional Tracking\n    - Interviews and Focus Groups\n    - Observation\n    - Online Tracking\n    - Forms\n    - Social Media Monitoring\n    - Application Programming Interface\n\n# Application Programming Interface (API)\n\n- APIs are mechanisms that enable two software components to communicate with each other using a set of definitions and protocols. For example, the weather bureau’s software system contains daily weather data. The weather app on your phone “talks” to this system via APIs and shows you daily weather updates on your phone.\n- API stands for Application Programming Interface. In the context of APIs, the word Application refers to any software with a distinct function. Interface can be thought of as a contract of service between two applications. This contract defines how the two communicate with each other using requests and responses. Their API documentation contains information on how developers are to structure those requests and responses.\n- API architecture is usually explained in terms of client and server. The application sending the request is called the client, and the application sending the response is called the server. So in the weather example, the bureau’s weather database is the server, and the mobile app is the client. \n- `Type of APIs:`\n    - **SOAP APIs:** These APIs use Simple Object Access Protocol. Client and server exchange messages using XML. This is a less flexible API that was more popular in the past.\n    - **RPC APIs:** These APIs are called Remote Procedure Calls. The client completes a function (or procedure) on the server, and the server sends the output back to the client.\n    - **Websocket APIs:** Websocket API is another modern web API development that uses JSON objects to pass data. A WebSocket API supports two-way communication between client apps and the server. The server can send callback messages to connected clients, making it more efficient than REST API.\n    - **REST APIs:** These are the most popular and flexible APIs found on the web today. The client sends requests to the server as data. The server uses this client input to start internal functions and returns output data back to the client. Let’s look at REST APIs in more detail below.\n- `What are REST APIs?`<br>\nREST stands for Representational State Transfer. REST defines a set of functions like GET, PUT, DELETE, etc. that clients can use to access server data. Clients and servers exchange data using HTTP. The main feature of REST API is statelessness. Statelessness means that servers do not save client data between requests. Client requests to the server are similar to URLs you type in your browser to visit a website. The response from the server is plain data, without the typical graphical rendering of a web page.\n\n# Import Libraries\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport requests\nimport pandas as pd\nimport numpy as np\nimport json\n```\n:::\n\n\n# Data Extraction from Ergast API\n- The Ergast Developer API is an experimental web service which provides a historical record of motor racing data for non-commercial purposes. The API provides data for the Formula One series, from the beginning of the world championships in 1950. I used the requests library in python to get the information from this API.\n- From this API we do not need the entire data as some of it is redundant and are available in every table. We need information about:\n    - All the Races since 1950 per season.\n    - All the Qualifiers\n    - All the Circuits\n    - All the Driver Standings\n    - All the Constructor Standings\n    - All the Seasons\n\n## Race Information\nThere are 2 main things in a Formula 1. The first is Season and the second is Round. There are multiple rounds (also called as Races) in every season and every Season happends once a year. The data contains the information about every round of every season such as race name, circuit information, date and the results.\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\ndef get_race_results(url, offset, limit=1000):\n    \n    result = requests.get(url + str(limit) + '&offset=' + str(offset))\n    \n    return result.json()\n```\n:::\n\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\nrecent_race_json = get_race_results(url = 'http://ergast.com/api/f1/results.json?limit=', offset = 25000)\n\nwith open('../../data/00-raw-data/race_data.json', 'w') as outfile:\n    json.dump(recent_race_json, outfile)\n```\n:::\n\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\ndef all_races():\n    \n    limit = 1000\n    result = []\n    length_per_page = []\n    url = 'http://ergast.com/api/f1/results.json?limit='\n    \n    p = 0\n    \n    while p < 100:\n        \n        page_result_json = get_race_results(url = url, offset = p*1000)\n        list_per_page = page_result_json['MRData']['RaceTable']['Races']\n    \n        if len(list_per_page) == 0:\n            break\n        \n        length_per_page.append(len(list_per_page))\n        \n        for i in range(len(list_per_page)):\n            result.append(list_per_page[i])\n        \n        p = p + 1\n        \n\n        \n    return result, length_per_page\n```\n:::\n\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\nresult_all_races,length_per_page = all_races()\n```\n:::\n\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\nrace_result_df = pd.DataFrame(result_all_races)\nrace_result_df.to_csv('../../data/00-raw-data/race_results.csv')\n```\n:::\n\n\n## Qualifying Information\nBefore every main Race of a season, there is a Qualifier where each driver races around the whole Circuit to set the fastest lap time. This determines the position that the driver is going to be starting on the Race day. The Qualifiers were fully implemented properly from the 2003 season onwards so there is no data available for seasons before 2003.\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\ndef get_qual_results(url, offset, limit=1000):\n    \n    result = requests.get(url + str(limit) + '&offset=' + str(offset))\n    \n    return result.json()\n```\n:::\n\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\nrecent_qual_json = get_qual_results(url = 'http://ergast.com/api/f1/qualifying.json?limit=', offset = 9000)\n\nwith open('../../data/00-raw-data/qual_data.json', 'w') as outfile:\n    json.dump(recent_qual_json, outfile)\n```\n:::\n\n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\ndef all_qual():\n    \n    limit = 1000\n    result = []\n    length_per_page = []\n    url = 'http://ergast.com/api/f1/qualifying.json?limit='\n    \n    p = 0\n    \n    while p < 100:\n        \n        page_result_json = get_qual_results(url = url, offset = p*1000)\n        list_per_page = page_result_json['MRData']['RaceTable']['Races']\n    \n        if len(list_per_page) == 0:\n            break\n        \n        length_per_page.append(len(list_per_page))\n        \n        for i in range(len(list_per_page)):\n            result.append(list_per_page[i])\n        \n        p = p + 1\n        \n\n        \n    return result, length_per_page\n```\n:::\n\n\n::: {.cell execution_count=10}\n``` {.python .cell-code}\nresult_all_qual,length_per_page = all_qual()\n```\n:::\n\n\n::: {.cell execution_count=11}\n``` {.python .cell-code}\nqual_result_df = pd.DataFrame(result_all_qual)\n```\n:::\n\n\n::: {.cell execution_count=12}\n``` {.python .cell-code}\nqual_result_df.to_csv('../../data/00-raw-data/qual_results.csv')\n```\n:::\n\n\n## Circuit Information\nThe tracks where each race is conducted on are knows as Circuits. The track owners have to renew their contract each year with the FIA to keep their track as one of the tracks where the Races will be held. The data has columns such as id of the circuit, the location and so on.\n\n::: {.cell execution_count=13}\n``` {.python .cell-code}\ndef get_circuit_info(url, offset, limit=1000):\n    \n    result = requests.get(url + str(limit) + '&offset=' + str(offset))\n    \n    return result.json()\n```\n:::\n\n\n::: {.cell execution_count=14}\n``` {.python .cell-code}\ncircuit_json = get_qual_results(url = 'http://ergast.com/api/f1/circuits.json?limit=', offset = 0)\n\nwith open('../../data/00-raw-data/circuit_data.json', 'w') as outfile:\n    json.dump(circuit_json, outfile)\n```\n:::\n\n\n::: {.cell execution_count=15}\n``` {.python .cell-code}\ncircuit_list = circuit_json['MRData']['CircuitTable']['Circuits']\n```\n:::\n\n\n::: {.cell execution_count=16}\n``` {.python .cell-code}\ncircuit_df = pd.DataFrame(circuit_list)\n```\n:::\n\n\n::: {.cell execution_count=17}\n``` {.python .cell-code}\ncircuit_df.to_csv('../../data/00-raw-data/circuit_info.csv')\n```\n:::\n\n\n## Driver Standings Information\nAfter each Round, points are allocated to winners of the race that follow a set of rules. All the points are combined at the end of every season for the World Driver's Championship. The driver with the highest points wins the WDC. This data contains the standings and points of each driver that competed in each season at the end of season.\n\n::: {.cell execution_count=18}\n``` {.python .cell-code}\ndef get_driverstanding_info(url, offset, limit=1000):\n    \n    result = requests.get(url + str(limit) + '&offset=' + str(offset))\n    \n    return result.json()\n```\n:::\n\n\n::: {.cell execution_count=19}\n``` {.python .cell-code}\ndriverstanding_json = get_driverstanding_info(url = 'http://ergast.com/api/f1/driverStandings.json?limit=', offset = 2000)\n\nwith open('../../data/00-raw-data/driverstanding_data.json', 'w') as outfile:\n    json.dump(driverstanding_json, outfile)\n```\n:::\n\n\n::: {.cell execution_count=20}\n``` {.python .cell-code}\ndef all_driverstandings():\n    \n    limit = 1000\n    result = []\n    length_per_page = []\n    url = 'http://ergast.com/api/f1/driverStandings.json?limit='\n    \n    p = 0\n    \n    while p < 100:\n        \n        page_result_json = get_driverstanding_info(url = url, offset = p*1000)\n        list_per_page = page_result_json['MRData']['StandingsTable']['StandingsLists']\n    \n        if len(list_per_page) == 0:\n            break\n        \n        length_per_page.append(len(list_per_page))\n        \n        for i in range(len(list_per_page)):\n            result.append(list_per_page[i])\n        \n        p = p + 1\n        \n\n        \n    return result, length_per_page\n```\n:::\n\n\n::: {.cell execution_count=21}\n``` {.python .cell-code}\nresult_all_driverstandings,length_per_page = all_driverstandings()\n```\n:::\n\n\n::: {.cell execution_count=22}\n``` {.python .cell-code}\ndriver_standings_df = pd.DataFrame(result_all_driverstandings)\n```\n:::\n\n\n::: {.cell execution_count=23}\n``` {.python .cell-code}\ndriver_standings_df.to_csv('../../data/00-raw-data/driver_standings.csv')\n```\n:::\n\n\n## Constructor Standings\nA Constructor in F1 is a term for teams. Each constructor has 2 drivers with identical cars competing in a season. At the end of the season the points of both the drivers are combined for the Constructor's Cup. The team with the highest points wins that cup. This data contains the standings and points of every Constructor that competed in each season at the end of season.\n\n::: {.cell execution_count=24}\n``` {.python .cell-code}\ndef get_constructorstanding_info(url, offset, limit=1000):\n    \n    result = requests.get(url + str(limit) + '&offset=' + str(offset))\n    \n    return result.json()\n```\n:::\n\n\n::: {.cell execution_count=25}\n``` {.python .cell-code}\nconstructortanding_json = get_constructorstanding_info(url = 'http://ergast.com/api/f1/constructorStandings.json?limit=', offset = 0)\n\nwith open('../../data/00-raw-data/constructorstanding_data.json', 'w') as outfile:\n    json.dump(constructortanding_json, outfile)\n```\n:::\n\n\n::: {.cell execution_count=26}\n``` {.python .cell-code}\nconstructortanding_list = constructortanding_json['MRData']['StandingsTable']['StandingsLists']\n```\n:::\n\n\n::: {.cell execution_count=27}\n``` {.python .cell-code}\nconstructortanding_df = pd.DataFrame(constructortanding_list)\n```\n:::\n\n\n::: {.cell execution_count=28}\n``` {.python .cell-code}\nconstructortanding_df.to_csv('../../data/00-raw-data/constructor_standings.csv')\n```\n:::\n\n\n## Season Information\nEvery season there is either new set of drivers or tracks or rules. This data has all the information of the tracks of all the rounds of every season.\n\n::: {.cell execution_count=29}\n``` {.python .cell-code}\ndef get_season_info(url, offset, limit=1000):\n    \n    result = requests.get(url + str(limit) + '&offset=' + str(offset))\n    \n    return result.json()\n```\n:::\n\n\n::: {.cell execution_count=30}\n``` {.python .cell-code}\ndef get_each_season_info(url, offset, season, limit=1000):\n    \n    result = requests.get(url + season + '.json?limit=' + str(limit) + '&offset=' + str(offset))\n    \n    return result.json()\n```\n:::\n\n\n::: {.cell execution_count=31}\n``` {.python .cell-code}\nseason_json = get_season_info(url = 'http://ergast.com/api/f1/seasons.json?limit=', offset = 0)\n\nwith open('../../data/00-raw-data/season_data.json', 'w') as outfile:\n    json.dump(season_json, outfile)\n```\n:::\n\n\n::: {.cell execution_count=32}\n``` {.python .cell-code}\nseason_list = season_json['MRData']['SeasonTable']['Seasons']\n```\n:::\n\n\n::: {.cell execution_count=33}\n``` {.python .cell-code}\nseason_df = pd.DataFrame(season_list)\n```\n:::\n\n\n::: {.cell execution_count=34}\n``` {.python .cell-code}\nseason_df.to_csv('../../data/00-raw-data/season_info.csv')\n```\n:::\n\n\n::: {.cell execution_count=35}\n``` {.python .cell-code}\nall_season_list = []\n\nfor i in range(len(season_df)):\n    \n    temp_json = get_each_season_info(url = 'http://ergast.com/api/f1/', season = season_df['season'][i], offset = 0)\n    temp_list = temp_json['MRData']['RaceTable']['Races']\n    \n    for j in range(len(temp_list)):\n        \n        all_season_list.append(temp_list[j])\n```\n:::\n\n\n::: {.cell execution_count=36}\n``` {.python .cell-code}\nall_season_df = pd.DataFrame(all_season_list)\n```\n:::\n\n\n::: {.cell execution_count=37}\n``` {.python .cell-code}\nall_season_df\n```\n\n::: {.cell-output .cell-output-display execution_count=37}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>season</th>\n      <th>round</th>\n      <th>url</th>\n      <th>raceName</th>\n      <th>Circuit</th>\n      <th>date</th>\n      <th>time</th>\n      <th>FirstPractice</th>\n      <th>SecondPractice</th>\n      <th>ThirdPractice</th>\n      <th>Qualifying</th>\n      <th>Sprint</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1950</td>\n      <td>1</td>\n      <td>http://en.wikipedia.org/wiki/1950_British_Gran...</td>\n      <td>British Grand Prix</td>\n      <td>{'circuitId': 'silverstone', 'url': 'http://en...</td>\n      <td>1950-05-13</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1950</td>\n      <td>2</td>\n      <td>http://en.wikipedia.org/wiki/1950_Monaco_Grand...</td>\n      <td>Monaco Grand Prix</td>\n      <td>{'circuitId': 'monaco', 'url': 'http://en.wiki...</td>\n      <td>1950-05-21</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1950</td>\n      <td>3</td>\n      <td>http://en.wikipedia.org/wiki/1950_Indianapolis...</td>\n      <td>Indianapolis 500</td>\n      <td>{'circuitId': 'indianapolis', 'url': 'http://e...</td>\n      <td>1950-05-30</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1950</td>\n      <td>4</td>\n      <td>http://en.wikipedia.org/wiki/1950_Swiss_Grand_...</td>\n      <td>Swiss Grand Prix</td>\n      <td>{'circuitId': 'bremgarten', 'url': 'http://en....</td>\n      <td>1950-06-04</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1950</td>\n      <td>5</td>\n      <td>http://en.wikipedia.org/wiki/1950_Belgian_Gran...</td>\n      <td>Belgian Grand Prix</td>\n      <td>{'circuitId': 'spa', 'url': 'http://en.wikiped...</td>\n      <td>1950-06-18</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1097</th>\n      <td>2023</td>\n      <td>19</td>\n      <td>https://en.wikipedia.org/wiki/2023_United_Stat...</td>\n      <td>United States Grand Prix</td>\n      <td>{'circuitId': 'americas', 'url': 'http://en.wi...</td>\n      <td>2023-10-22</td>\n      <td>19:00:00Z</td>\n      <td>{'date': '2023-10-20', 'time': '17:30:00Z'}</td>\n      <td>{'date': '2023-10-21', 'time': '18:00:00Z'}</td>\n      <td>NaN</td>\n      <td>{'date': '2023-10-20', 'time': '21:00:00Z'}</td>\n      <td>{'date': '2023-10-21', 'time': '22:00:00Z'}</td>\n    </tr>\n    <tr>\n      <th>1098</th>\n      <td>2023</td>\n      <td>20</td>\n      <td>https://en.wikipedia.org/wiki/2023_Mexico_City...</td>\n      <td>Mexico City Grand Prix</td>\n      <td>{'circuitId': 'rodriguez', 'url': 'http://en.w...</td>\n      <td>2023-10-29</td>\n      <td>20:00:00Z</td>\n      <td>{'date': '2023-10-27', 'time': '18:30:00Z'}</td>\n      <td>{'date': '2023-10-27', 'time': '22:00:00Z'}</td>\n      <td>{'date': '2023-10-28', 'time': '17:30:00Z'}</td>\n      <td>{'date': '2023-10-28', 'time': '21:00:00Z'}</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1099</th>\n      <td>2023</td>\n      <td>21</td>\n      <td>https://en.wikipedia.org/wiki/2023_S%C3%A3o_Pa...</td>\n      <td>São Paulo Grand Prix</td>\n      <td>{'circuitId': 'interlagos', 'url': 'http://en....</td>\n      <td>2023-11-05</td>\n      <td>17:00:00Z</td>\n      <td>{'date': '2023-11-03', 'time': '14:30:00Z'}</td>\n      <td>{'date': '2023-11-04', 'time': '14:30:00Z'}</td>\n      <td>NaN</td>\n      <td>{'date': '2023-11-03', 'time': '18:00:00Z'}</td>\n      <td>{'date': '2023-11-04', 'time': '18:30:00Z'}</td>\n    </tr>\n    <tr>\n      <th>1100</th>\n      <td>2023</td>\n      <td>22</td>\n      <td>https://en.wikipedia.org/wiki/2023_Las_Vegas_G...</td>\n      <td>Las Vegas Grand Prix</td>\n      <td>{'circuitId': 'vegas', 'url': 'https://en.wiki...</td>\n      <td>2023-11-19</td>\n      <td>06:00:00Z</td>\n      <td>{'date': '2023-11-17', 'time': '04:30:00Z'}</td>\n      <td>{'date': '2023-11-17', 'time': '08:00:00Z'}</td>\n      <td>{'date': '2023-11-18', 'time': '04:30:00Z'}</td>\n      <td>{'date': '2023-11-18', 'time': '08:00:00Z'}</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1101</th>\n      <td>2023</td>\n      <td>23</td>\n      <td>https://en.wikipedia.org/wiki/2023_Abu_Dhabi_G...</td>\n      <td>Abu Dhabi Grand Prix</td>\n      <td>{'circuitId': 'yas_marina', 'url': 'http://en....</td>\n      <td>2023-11-26</td>\n      <td>13:00:00Z</td>\n      <td>{'date': '2023-11-24', 'time': '09:30:00Z'}</td>\n      <td>{'date': '2023-11-24', 'time': '13:00:00Z'}</td>\n      <td>{'date': '2023-11-25', 'time': '10:30:00Z'}</td>\n      <td>{'date': '2023-11-25', 'time': '14:00:00Z'}</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>1102 rows × 12 columns</p>\n</div>\n```\n:::\n:::\n\n\n::: {.cell execution_count=38}\n``` {.python .cell-code}\nall_season_df.to_csv('../../data/00-raw-data/all_season_info.csv')\n```\n:::\n\n\n",
    "supporting": [
      "record_datagathering_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}